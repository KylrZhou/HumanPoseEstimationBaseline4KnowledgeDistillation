{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6375be-550e-4f96-946c-c04e96ffc1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, BatchNorm2d, ReLU, MaxPool2d, Sequential, AdaptiveAvgPool2d, Linear, Softmax, CrossEntropyLoss, MSELoss, NLLLoss\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomHorizontalFlip, RandomGrayscale, Resize, InterpolationMode\n",
    "from torch.cuda import memory_allocated, empty_cache, memory_reserved, IntTensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Adam, SGD, lr_scheduler\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "973e3f1c-8497-41d3-9875-277921ac7003",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transform_Train = Compose([RandomHorizontalFlip(),\n",
    "                           RandomGrayscale(),\n",
    "                           ToTensor(),\n",
    "                           Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "Transform_Test = Compose([ToTensor(),\n",
    "                           Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "log_interval = 10\n",
    "momentum = 0.9\n",
    "TrainBS = 8\n",
    "TestBS = 64\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "190fce8e-83d5-41a9-be02-bcd021621d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./log/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30cfedaf-8db0-4841-a41b-361e1b4f4e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "Train_Data = DataLoader(dataset = CIFAR10(root = './data/',\n",
    "                                          train = True,\n",
    "                                          transform = Transform_Train,\n",
    "                                          download = True),\n",
    "                        batch_size = TrainBS,\n",
    "                        shuffle = True)\n",
    "Test_Data = DataLoader(dataset = CIFAR10(root = './data/',\n",
    "                                          train = False,\n",
    "                                          transform = Transform_Test,\n",
    "                                          download = True),\n",
    "                        batch_size = TestBS,\n",
    "                        shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "499fc50c-c416-4ce8-bae2-e599a77ccb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, DownSample, Proc_Channel):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        stride = 1\n",
    "        self.shortcut = Sequential()\n",
    "        in_channels = Proc_Channel\n",
    "        if DownSample == 1:\n",
    "            if Proc_Channel != 64:\n",
    "                in_channels = int(Proc_Channel/2)\n",
    "                stride = 2\n",
    "            self.shortcut = Sequential(Conv2d(in_channels = in_channels, out_channels = Proc_Channel, kernel_size = 3, stride = stride, padding = 1),\n",
    "                                       BatchNorm2d(Proc_Channel))    \n",
    "        kernel_size = 3\n",
    "        self.ConvLayer1 = Conv2d(in_channels, Proc_Channel, kernel_size, stride, 1)\n",
    "        self.BatchNorm1 = BatchNorm2d(Proc_Channel)\n",
    "        self.ConvLayer2 = Conv2d(in_channels = Proc_Channel, out_channels = Proc_Channel, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.BatchNorm2 = BatchNorm2d(Proc_Channel)\n",
    "        self.BatchNorm3 = BatchNorm2d(Proc_Channel)\n",
    "    def forward(self, x):\n",
    "        Residual = self.shortcut(x)\n",
    "        x = self.ConvLayer1(x)\n",
    "        x = self.BatchNorm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.ConvLayer2(x)\n",
    "        x = self.BatchNorm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = x + Residual\n",
    "        x = self.BatchNorm3(x)\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64593901-c321-4834-8c03-961cb247efa5",
   "metadata": {},
   "source": [
    "![resnet.png](\"C:\\Users\\Baaaatttlllllllleeee\\Pictures\\resnet.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b421de33-3dd7-405e-836a-efdf84cd81fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self,DownSample,Proc_Channel):\n",
    "        super(Bottleneck,self).__init__()\n",
    "        Proc_Channel = int(Proc_Channel / 4)\n",
    "        stride = 1\n",
    "        in_channels = int(Proc_Channel * 4)\n",
    "        if DownSample == 1:\n",
    "            if Proc_Channel == 64:\n",
    "                in_channels = Proc_Channel\n",
    "            else:\n",
    "                stride = 2\n",
    "                in_channels = int(Proc_Channel * 2)\n",
    "        self.ConvLayer1 = Sequential(Conv2d(in_channels, Proc_Channel, 1, 1, 0),\n",
    "                                     BatchNorm2d(Proc_Channel), \n",
    "                                     ReLU())\n",
    "        self.ConvLayer2 = Sequential(Conv2d(Proc_Channel, Proc_Channel, 3, stride, 1),\n",
    "                                     BatchNorm2d(Proc_Channel), \n",
    "                                     ReLU())\n",
    "        self.ConvLayer3 = Sequential(Conv2d(Proc_Channel, Proc_Channel * 4, 1, 1, 0),\n",
    "                                     BatchNorm2d(Proc_Channel * 4), \n",
    "                                     ReLU())\n",
    "        self.shortcut = Sequential(Conv2d(in_channels, Proc_Channel * 4, 3, stride, 1),\n",
    "                                   BatchNorm2d(Proc_Channel * 4))\n",
    "        self.Post = Sequential(BatchNorm2d(Proc_Channel * 4),\n",
    "                               ReLU())\n",
    "    def forward(self,x):\n",
    "        Residual = self.shortcut(x)\n",
    "        x = self.ConvLayer1(x)\n",
    "        x = self.ConvLayer2(x)\n",
    "        x = self.ConvLayer3(x)\n",
    "        x = x + Residual\n",
    "        x = self.Post(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed833dc1-4c0e-4249-bbb8-eedcdfabac0b",
   "metadata": {},
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, DownSample, Proc_Channel):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        Proc_Channel = int(Proc_Channel / 4)\n",
    "        stride = 1\n",
    "        in_channels = Proc_Channel * 4\n",
    "        if DownSample == 1:\n",
    "            stride = 2\n",
    "            in_channels = int(Proc_Channel * 2)\n",
    "            if Proc_Channel == 64:\n",
    "                stride = 1\n",
    "                in_channels = Proc_Channel\n",
    "            self.shortcut = Sequential(Conv2d(in_channels = in_channels, out_channels = Proc_Channel * 4, kernel_size = 3, stride = stride, padding = 1),\n",
    "                                       BatchNorm2d(Proc_Channel * 4))\n",
    "        else:\n",
    "            self.shortcut = Sequential(Conv2d(in_channels = in_channels, out_channels = Proc_Channel * 4, kernel_size = 3, stride = stride, padding = 1),\n",
    "                                       BatchNorm2d(Proc_Channel * 4))\n",
    "        self.ConvLayer1 = Sequential(Conv2d(in_channels = in_channels, out_channels = Proc_Channel, kernel_size = 1, stride = 1, padding = 0),\n",
    "                                     BatchNorm2d(Proc_Channel),\n",
    "                                     ReLU())\n",
    "        self.ConvLayer2 = Sequential(Conv2d(in_channels = Proc_Channel, out_channels = Proc_Channel, kernel_size = 3, stride = stride, padding = 1),\n",
    "                                     BatchNorm2d(Proc_Channel),\n",
    "                                     ReLU())\n",
    "        self.ConvLayer3 = Sequential(Conv2d(in_channels = Proc_Channel, out_channels = Proc_Channel * 4, kernel_size = 1, stride = 1, padding = 0),\n",
    "                                     BatchNorm2d(Proc_Channel * 4))\n",
    "        self.Res_Proc = Sequential(BatchNorm2d(Proc_Channel * 4),\n",
    "                                   ReLU())\n",
    "    def forward(self, x):\n",
    "        Residual = self.shortcut(x)\n",
    "        x = self.ConvLayer1(x)\n",
    "        x = self.ConvLayer2(x)\n",
    "        x = self.ConvLayer3(x)\n",
    "        x = x + Residual\n",
    "        x = self.Res_Proc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ff9f20-fe93-44e3-ac0b-0bfaf867c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layer_arch, final_output): \n",
    "        super(ResNet, self).__init__()\n",
    "        self.final_output = final_output\n",
    "        self.Resize = Resize((224,224), interpolation = InterpolationMode.BILINEAR)\n",
    "        self.stem = Sequential(Conv2d(in_channels = 3, out_channels = 64, kernel_size = 7, stride = 2, padding =3),\n",
    "                               BatchNorm2d(64),\n",
    "                               ReLU(),\n",
    "                               MaxPool2d(kernel_size = 3, stride = 2, padding = 1))\n",
    "        self.stage1 = self._make_layer(block, layer_arch[0], int(self.final_output / 8))\n",
    "        self.stage2 = self._make_layer(block, layer_arch[1], int(self.final_output / 4))\n",
    "        self.stage3 = self._make_layer(block, layer_arch[2], int(self.final_output / 2))\n",
    "        self.stage4 = self._make_layer(block, layer_arch[3], self.final_output)\n",
    "        self.AvgPool = AdaptiveAvgPool2d((1,1))\n",
    "        self.fc1 = Linear(self.final_output, 1000)\n",
    "        self.fc2 = Linear(1000,10)\n",
    "        self.softmax = Softmax(dim = 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.Resize(x)\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.AvgPool(x)\n",
    "        x = x.view(-1,self.final_output)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    def _make_layer(self, block, layer_arch, Proc_Channel):\n",
    "        layer = Sequential()\n",
    "        for i in range(layer_arch):\n",
    "            if i == 0:\n",
    "                layer.append(block(True, Proc_Channel))\n",
    "            else:\n",
    "                layer.append(block(False, Proc_Channel))\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bedef48f-27cb-47fe-ac52-815cf55426a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2], 512)\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3,4,6,3], 512)\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3,4,6,3] , 2048)\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3,4,23,3] , 2048)\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3,8,36,3] , 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fed9fb90-09f4-43f4-8019-6c970a53d77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "Network = ResNet50()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "Network.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b4671a-80b3-4318-926e-cb28bd7ab790",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = CrossEntropyLoss()\n",
    "#loss_function =  MSELoss() # Failed\n",
    "#loss_function = NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "845a968c-cefa-4736-a4d7-169312588efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_counter = []\n",
    "train_loss_counter = []\n",
    "train_data_counter = []\n",
    "test_acc_counter = []\n",
    "test_data_counter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6659bf0f-7c34-4759-927a-99bb65bb11dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    Network.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        for data, target in Test_Data:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = Network(data).to(device)\n",
    "            output = output.data.max(1, keepdim = True)[1]\n",
    "            correct += output.eq(target.data.view_as(output)).sum()\n",
    "        log = \"Mode: Test | Epoch:{} Memory:{:.0f}MB Acc:{:.0f}%\".format(epoch,  memory_allocated(device)/1048576, 100. * correct/len(Test_Data.dataset))\n",
    "        writer.add_scalar(tag = 'TestAccuracy', scalar_value=(100. * correct/len(Test_Data.dataset)), global_step=(epoch * len(Train_Data.dataset)))\n",
    "        print(log)\n",
    "        test_acc_counter.append((100. * correct/len(Test_Data.dataset)))\n",
    "        test_data_counter.append(epoch * len(Train_Data.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bafe5ee-946d-4c43-bb05-62a35b93706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    for epoch in range(1, epochs+1):\n",
    "        Network.train()\n",
    "        empty_cache()\n",
    "        for batch_idx, (data, target) in enumerate(Train_Data):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            correct = 0\n",
    "            output = Network(data)\n",
    "            pred = output.data.max(1, keepdim = True)[1]\n",
    "            pred = pred.view_as(target)\n",
    "            correct += pred.eq(target.data).sum()\n",
    "            correct = int(correct)\n",
    "            loss = loss_function(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0 and batch_idx != 0:\n",
    "                log = \"Mode: Train | Epoch:{} Data:{}/{} Memory:{:.0f}MB Accuracy:{:.0f}% Loss:{:.6f}\".format(epoch, batch_idx*len(data), len(Train_Data.dataset), memory_allocated(device)/1048576, 100. * (correct/len(data)), loss.item())\n",
    "                print(log)\n",
    "                train_acc_counter.append((100. * (correct/len(data))))\n",
    "                train_loss_counter.append(loss.item())\n",
    "                train_data_counter.append((epoch-1) * len(Train_Data.dataset) + batch_idx * len(data))\n",
    "                writer.add_scalar(tag = 'TrainAccuracy', scalar_value=(100. * (correct/len(data))), global_step=(epoch-1) * len(Train_Data.dataset) + batch_idx * len(data))\n",
    "                writer.add_scalar(tag = 'TrainLoss', scalar_value=loss.item(), global_step=(epoch-1) * len(Train_Data.dataset) + batch_idx * len(data))\n",
    "        empty_cache()\n",
    "        test(epoch)\n",
    "        scheduler.step()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b32e68dc-cbec-4877-a34c-8121e60d1ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(params = Network.parameters(), lr = lr) \n",
    "#optimizer = SGD(params = Network.parameters(), lr = lr, momentum = momentum)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425640c-391a-4760-9794-63565c24fd9e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: Train | Epoch:1 Data:80/50000 Memory:2735MB Accuracy:0% Loss:2.301190\n",
      "Mode: Train | Epoch:1 Data:160/50000 Memory:2735MB Accuracy:12% Loss:2.302492\n",
      "Mode: Train | Epoch:1 Data:240/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:320/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:400/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:480/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:560/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:640/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:720/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:800/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:880/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:960/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:1040/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:1120/50000 Memory:2735MB Accuracy:25% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:1200/50000 Memory:2735MB Accuracy:38% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:1280/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:1360/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:1440/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:1520/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:1600/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:1680/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:1760/50000 Memory:2735MB Accuracy:25% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:1840/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:1920/50000 Memory:2735MB Accuracy:38% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:2000/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:2080/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:2160/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:2240/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:2320/50000 Memory:2735MB Accuracy:25% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:2400/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:2480/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:2560/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:2640/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:2720/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:2800/50000 Memory:2735MB Accuracy:38% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:2880/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:2960/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:3040/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:3120/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:3200/50000 Memory:2735MB Accuracy:25% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:3280/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:3360/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:3440/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:3520/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:3600/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:3680/50000 Memory:2735MB Accuracy:25% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:3760/50000 Memory:2735MB Accuracy:25% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:3840/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:3920/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:4000/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:4080/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:4160/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:4240/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:4320/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:4400/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:4480/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:4560/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:4640/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:4720/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:4800/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:4880/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:4960/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:5040/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:5120/50000 Memory:2735MB Accuracy:25% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:5200/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:5280/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:5360/50000 Memory:2735MB Accuracy:0% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:5440/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n",
      "Mode: Train | Epoch:1 Data:5520/50000 Memory:2735MB Accuracy:12% Loss:2.302585\n"
     ]
    }
   ],
   "source": [
    "train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfceebe-b1df-475d-a454-6e427c2f052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(memory_allocated(device)/1048576)\n",
    "print(memory_reserved(device)/1048576)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660232f9-4c12-4ec6-9ac1-40b1d99184b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d3b456-a483-4ce4-93b9-84e1f2c1dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Network.to('cpu')\n",
    "empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3981259b-8e4b-4ec6-bd5e-fec0edd12c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
